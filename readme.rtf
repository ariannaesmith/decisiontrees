{\rtf1\ansi\ansicpg1252\cocoartf2511
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Created by: Arianna Smith\
CSE 6375\
\
Homework 1\
A program to implement the decision tree algorithm with both information gain and variance impurity, reduced-error post pruning, depth-based pruning, and scikit-learn random forests.\
\
To run:\
Have all datasets and .py files in the same folder. From command line, navigate to the folder and then run as arguments:\
0- drivercode.py\
1- \'93clause size\'94\
2- \'93sample number\'94\
3- RF *or* \'93impurity type\'94\
4- \'93prune method\'94\
\
\'93Clause size\'94 options are: c300, c500, c1000, c1500, c1800\
\'93Sample number\'94 options are: d00, d1000, d5000\
\'93Impurity type\'94 options are: entropy, variance\
\'93Prune method\'94 options are: error, depth, none\
\
\
Written with: Python 3.7\
Written in: Spyder 3.3.6\
Written on: macOS Catalina Version 10.15.1\
\
\
Files: \
decisiontree.py\
drivercode.py\
heuristics.py\
pruning.py\
randomforests.py\
testfunction.py\
\
test_c300_d100.csv\
test_c300_d1000.csv\
test_c300_d5000.csv\
test_c500_d100.csv\
test_c500_d1000.csv\
test_c500_d5000.csv\
test_c1000_d100.csv\
test_c1000_d1000.csv\
test_c1000_d5000.csv\
test_c1500_d100.csv\
test_c1500_d1000.csv\
test_c1500_d5000.csv\
test_c1800_d100.csv\
test_c1800_d1000.csv\
test_c1800_d5000.csv\
train_c300_d100.csv\
train_c300_d1000.csv\
train_c300_d5000.csv\
train_c500_d100.csv\
train_c500_d1000.csv\
train_c500_d5000.csv\
train_c1000_d100.csv\
train_c1000_d1000.csv\
train_c1000_d5000.csv\
train_c1500_d100.csv\
train_c1500_d1000.csv\
train_c1500_d5000.csv\
train_c1800_d100.csv\
train_c1800_d1000.csv\
train_c1800_d5000.csv\
valid_c300_d100.csv\
valid_c300_d1000.csv\
valid_c300_d5000.csv\
valid_c500_d100.csv\
valid_c500_d1000.csv\
valid_c500_d5000.csv\
valid_c1000_d100.csv\
valid_c1000_d1000.csv\
valid_c1000_d5000.csv\
valid_c1500_d100.csv\
valid_c1500_d1000.csv\
valid_c1500_d5000.csv\
valid_c1800_d100.csv\
valid_c1800_d1000.csv\
valid_c1800_d5000.csv}